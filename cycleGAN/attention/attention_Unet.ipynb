{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.8 64-bit ('tensor2': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "c6993ba8a3fd8114df041e36996b1c1fd361a4b09ce5d58bf9b5e95b488c6c30"
   }
  },
  "interpreter": {
   "hash": "368cec5af9d55f3645ce893451bf6ff97de02598cc0bc19aa254d796841e01eb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, UpSampling2D, BatchNormalization, Reshape, LeakyReLU, Activation, Input, add, multiply\n",
    "from tensorflow.keras.layers import concatenate, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Lambda\n",
    "import tensorflow.keras.backend as K\n",
    "import instancenormalization\n",
    "\n",
    "\n",
    "\n",
    "def up_and_concate(down_layer, layer, data_format='channels_last'):\n",
    "    if data_format == 'channels_first':\n",
    "        in_channel = down_layer.get_shape().as_list()[1]\n",
    "    else:\n",
    "        in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
    "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
    "    else:\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "\n",
    "    concate = my_concat([up, layer])\n",
    "\n",
    "    return concate\n",
    "\n",
    "\n",
    "def attention_up_and_concate(down_layer, layer, data_format='channels_last'):\n",
    "    if data_format == 'channels_first':\n",
    "        in_channel = down_layer.get_shape().as_list()[1]\n",
    "    else:\n",
    "        in_channel = down_layer.get_shape().as_list()[3]\n",
    "\n",
    "    # up = Conv2DTranspose(out_channel, [2, 2], strides=[2, 2])(down_layer)\n",
    "    up = UpSampling2D(size=(2, 2), data_format=data_format)(down_layer)\n",
    "\n",
    "    layer = attention_block_2d(x=layer, g=up, inter_channel=in_channel // 4, data_format=data_format)\n",
    "\n",
    "    if data_format == 'channels_first':\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=1))\n",
    "    else:\n",
    "        my_concat = Lambda(lambda x: K.concatenate([x[0], x[1]], axis=3))\n",
    "\n",
    "    concate = my_concat([up, layer])\n",
    "    return concate\n",
    "\n",
    "\n",
    "def attention_block_2d(x, g, inter_channel, data_format='channels_last'):\n",
    "    # theta_x(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    theta_x = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(x)\n",
    "\n",
    "    # phi_g(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    phi_g = Conv2D(inter_channel, [1, 1], strides=[1, 1], data_format=data_format)(g)\n",
    "\n",
    "    # f(?,g_height,g_width,inter_channel)\n",
    "\n",
    "    f = Activation(tf.nn.LeakyReLU)(add([theta_x, phi_g]))\n",
    "\n",
    "    # psi_f(?,g_height,g_width,1)\n",
    "\n",
    "    psi_f = Conv2D(1, [1, 1], strides=[1, 1], data_format=data_format)(f)\n",
    "\n",
    "    rate = Activation('sigmoid')(psi_f)\n",
    "\n",
    "    # rate(?,x_height,x_width)\n",
    "\n",
    "    # att_x(?,x_height,x_width,x_channel)\n",
    "\n",
    "    att_x = multiply([x, rate])\n",
    "\n",
    "    return att_x\n",
    "\n",
    "\n",
    "def att_unet(img_w, img_h, data_format='channels_last'):\n",
    "    inputs = Input((img_w, img_h, 3))\n",
    "    x = inputs\n",
    "    depth = 4\n",
    "    features = 32\n",
    "    skips = []\n",
    "    for i in range(depth):\n",
    "        x = Conv2D(features, 3, activation=LeakyReLU(), padding='same')(x)\n",
    "        x = instancenormalization.InstanceNormalization()(x)\n",
    "        x = Conv2D(features, 3, activation=LeakyReLU(), padding='same')(x)\n",
    "        x = instancenormalization.InstanceNormalization()(x)\n",
    "        skips.append(x)\n",
    "        x = MaxPooling2D(2)(x)\n",
    "        features = features * 2\n",
    "\n",
    "    x = Conv2D(features, (3, 3), activation=LeakyReLU(), padding='same', data_format=data_format)(x)\n",
    "    x = instancenormalization.InstanceNormalization()(x)\n",
    "    x = Conv2D(features, (3, 3), activation=LeakyReLU(), padding='same', data_format=data_format)(x)\n",
    "    x = instancenormalization.InstanceNormalization()(x)\n",
    "\n",
    "    for i in reversed(range(depth)):\n",
    "        features = features // 2\n",
    "        x = attention_up_and_concate(x, skips[i], data_format=data_format)\n",
    "        x = Conv2D(features, (3, 3), activation=LeakyReLU(), padding='same', data_format=data_format)(x)\n",
    "        x = instancenormalization.InstanceNormalization()(x)\n",
    "        x = Conv2D(features, (3, 3), activation=LeakyReLU(), padding='same', data_format=data_format)(x)\n",
    "        x = instancenormalization.InstanceNormalization()(x)\n",
    "\n",
    "    conv6 = Conv2D(3, (1, 1), padding='same', data_format=data_format)(x)\n",
    "    conv7 = Activation('tanh')(conv6)\n",
    "    model = Model(inputs=inputs, outputs=conv7)\n",
    "\n",
    "    #model.compile(optimizer=Adam(lr=1e-5), loss=[focal_loss()], metrics=['accuracy', dice_coef])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}